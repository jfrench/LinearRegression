<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>C Review of Estimation and Inference | A Progressive Introduction to Linear Models</title>
  <meta name="description" content="A collection of material that progressively introduces how to fit and use linear models." />
  <meta name="generator" content="bookdown 0.30 and GitBook 2.6.7" />

  <meta property="og:title" content="C Review of Estimation and Inference | A Progressive Introduction to Linear Models" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="A collection of material that progressively introduces how to fit and use linear models." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="C Review of Estimation and Inference | A Progressive Introduction to Linear Models" />
  
  <meta name="twitter:description" content="A collection of material that progressively introduces how to fit and use linear models." />
  

<meta name="author" content="Joshua French" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="prob-review.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Progressive Introduction to Linear Models</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preliminaries</a></li>
<li class="chapter" data-level="1" data-path="r-foundations.html"><a href="r-foundations.html"><i class="fa fa-check"></i><b>1</b> R Foundations</a>
<ul>
<li class="chapter" data-level="1.1" data-path="r-foundations.html"><a href="r-foundations.html#setting-up-r-and-rstudio-desktop"><i class="fa fa-check"></i><b>1.1</b> Setting up R and RStudio Desktop</a></li>
<li class="chapter" data-level="1.2" data-path="r-foundations.html"><a href="r-foundations.html#running-code-scripts-and-comments"><i class="fa fa-check"></i><b>1.2</b> Running code, scripts, and comments</a></li>
<li class="chapter" data-level="1.3" data-path="r-foundations.html"><a href="r-foundations.html#assignment"><i class="fa fa-check"></i><b>1.3</b> Assignment</a></li>
<li class="chapter" data-level="1.4" data-path="r-foundations.html"><a href="r-foundations.html#functions"><i class="fa fa-check"></i><b>1.4</b> Functions</a></li>
<li class="chapter" data-level="1.5" data-path="r-foundations.html"><a href="r-foundations.html#packages"><i class="fa fa-check"></i><b>1.5</b> Packages</a></li>
<li class="chapter" data-level="1.6" data-path="r-foundations.html"><a href="r-foundations.html#getting-help"><i class="fa fa-check"></i><b>1.6</b> Getting help</a></li>
<li class="chapter" data-level="1.7" data-path="r-foundations.html"><a href="r-foundations.html#data-types-and-structures"><i class="fa fa-check"></i><b>1.7</b> Data types and structures</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="r-foundations.html"><a href="r-foundations.html#basic-data-types"><i class="fa fa-check"></i><b>1.7.1</b> Basic data types</a></li>
<li class="chapter" data-level="1.7.2" data-path="r-foundations.html"><a href="r-foundations.html#other-important-object-types"><i class="fa fa-check"></i><b>1.7.2</b> Other important object types</a></li>
<li class="chapter" data-level="1.7.3" data-path="r-foundations.html"><a href="r-foundations.html#data-structures"><i class="fa fa-check"></i><b>1.7.3</b> Data structures</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="r-foundations.html"><a href="r-foundations.html#vectors"><i class="fa fa-check"></i><b>1.8</b> Vectors</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="r-foundations.html"><a href="r-foundations.html#creation"><i class="fa fa-check"></i><b>1.8.1</b> Creation</a></li>
<li class="chapter" data-level="1.8.2" data-path="r-foundations.html"><a href="r-foundations.html#categorical-vectors"><i class="fa fa-check"></i><b>1.8.2</b> Categorical vectors</a></li>
<li class="chapter" data-level="1.8.3" data-path="r-foundations.html"><a href="r-foundations.html#extracting-parts-of-a-vector"><i class="fa fa-check"></i><b>1.8.3</b> Extracting parts of a vector</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="r-foundations.html"><a href="r-foundations.html#helpful-functions"><i class="fa fa-check"></i><b>1.9</b> Helpful functions</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="r-foundations.html"><a href="r-foundations.html#general-functions"><i class="fa fa-check"></i><b>1.9.1</b> General functions</a></li>
<li class="chapter" data-level="1.9.2" data-path="r-foundations.html"><a href="r-foundations.html#functions-related-to-statistical-distributions"><i class="fa fa-check"></i><b>1.9.2</b> Functions related to statistical distributions</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="r-foundations.html"><a href="r-foundations.html#data-frames"><i class="fa fa-check"></i><b>1.10</b> Data Frames</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="r-foundations.html"><a href="r-foundations.html#direct-creation"><i class="fa fa-check"></i><b>1.10.1</b> Direct creation</a></li>
<li class="chapter" data-level="1.10.2" data-path="r-foundations.html"><a href="r-foundations.html#importing-data"><i class="fa fa-check"></i><b>1.10.2</b> Importing Data</a></li>
<li class="chapter" data-level="1.10.3" data-path="r-foundations.html"><a href="r-foundations.html#extracting-parts-of-a-data-frame"><i class="fa fa-check"></i><b>1.10.3</b> Extracting parts of a data frame</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="r-foundations.html"><a href="r-foundations.html#using-the-pipe-operator"><i class="fa fa-check"></i><b>1.11</b> Using the pipe operator</a></li>
<li class="chapter" data-level="1.12" data-path="r-foundations.html"><a href="r-foundations.html#dealing-with-common-problems"><i class="fa fa-check"></i><b>1.12</b> Dealing with common problems</a></li>
<li class="chapter" data-level="1.13" data-path="r-foundations.html"><a href="r-foundations.html#ecosystem-debate"><i class="fa fa-check"></i><b>1.13</b> Ecosystem debate</a></li>
<li class="chapter" data-level="1.14" data-path="r-foundations.html"><a href="r-foundations.html#additional-information"><i class="fa fa-check"></i><b>1.14</b> Additional information</a>
<ul>
<li class="chapter" data-level="1.14.1" data-path="r-foundations.html"><a href="r-foundations.html#comparing-assignment-operators"><i class="fa fa-check"></i><b>1.14.1</b> Comparing assignment operators</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html"><i class="fa fa-check"></i><b>2</b> Data cleaning and exploration</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#raw-palmer-penguins-data"><i class="fa fa-check"></i><b>2.1</b> Raw Palmer penguins data</a></li>
<li class="chapter" data-level="2.2" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#initial-data-cleaning"><i class="fa fa-check"></i><b>2.2</b> Initial data cleaning</a></li>
<li class="chapter" data-level="2.3" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#numerical-summarization-of-data"><i class="fa fa-check"></i><b>2.3</b> Numerical summarization of data</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#numeric-data"><i class="fa fa-check"></i><b>2.3.1</b> Numeric data</a></li>
<li class="chapter" data-level="2.3.2" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#categorical-data"><i class="fa fa-check"></i><b>2.3.2</b> Categorical data</a></li>
<li class="chapter" data-level="2.3.3" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#the-summary-function"><i class="fa fa-check"></i><b>2.3.3</b> The <code>summary</code> function</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#visual-summaries-of-data"><i class="fa fa-check"></i><b>2.4</b> Visual summaries of data</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#the-ggplot-recipe"><i class="fa fa-check"></i><b>2.4.1</b> The ggplot recipe</a></li>
<li class="chapter" data-level="2.4.2" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#univariate-plots"><i class="fa fa-check"></i><b>2.4.2</b> Univariate plots</a></li>
<li class="chapter" data-level="2.4.3" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#bivariate-plots"><i class="fa fa-check"></i><b>2.4.3</b> Bivariate plots</a></li>
<li class="chapter" data-level="2.4.4" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#multivariate-plots"><i class="fa fa-check"></i><b>2.4.4</b> Multivariate plots</a></li>
<li class="chapter" data-level="2.4.5" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#facetted-plots-and-alternatives"><i class="fa fa-check"></i><b>2.4.5</b> Facetted plots (and alternatives)</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#a-plan-for-data-cleaning-and-exploration"><i class="fa fa-check"></i><b>2.5</b> A plan for data cleaning and exploration</a></li>
<li class="chapter" data-level="2.6" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#final-notes-on-missing-or-erroneous-data"><i class="fa fa-check"></i><b>2.6</b> Final notes on missing or erroneous data</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html"><i class="fa fa-check"></i><b>3</b> Linear model estimation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#a-simple-motivating-example"><i class="fa fa-check"></i><b>3.1</b> A simple motivating example</a></li>
<li class="chapter" data-level="3.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#s-slr-estimation"><i class="fa fa-check"></i><b>3.2</b> Estimation of the simple linear regression model</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ss:fv-resid-rss"><i class="fa fa-check"></i><b>3.2.1</b> Model definition, fitted values, residuals, and RSS</a></li>
<li class="chapter" data-level="3.2.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ols-estimators-of-the-simple-linear-regression-parameters"><i class="fa fa-check"></i><b>3.2.2</b> OLS estimators of the simple linear regression parameters</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#s:penguins-slr"><i class="fa fa-check"></i><b>3.3</b> Penguins simple linear regression example</a></li>
<li class="chapter" data-level="3.4" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#defining-a-linear-model"><i class="fa fa-check"></i><b>3.4</b> Defining a linear model</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ss-necessary-components"><i class="fa fa-check"></i><b>3.4.1</b> Necessary components and notation</a></li>
<li class="chapter" data-level="3.4.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#standard-definition-of-linear-model"><i class="fa fa-check"></i><b>3.4.2</b> Standard definition of linear model</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#estimation-of-the-multiple-linear-regression-model"><i class="fa fa-check"></i><b>3.5</b> Estimation of the multiple linear regression model</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#using-matrix-notation-to-represent-a-linear-model"><i class="fa fa-check"></i><b>3.5.1</b> Using matrix notation to represent a linear model</a></li>
<li class="chapter" data-level="3.5.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ss:fv-resid-rss-mlr"><i class="fa fa-check"></i><b>3.5.2</b> Residuals, fitted values, and RSS for multiple linear regression</a></li>
<li class="chapter" data-level="3.5.3" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ols-estimator-of-the-regression-coefficients"><i class="fa fa-check"></i><b>3.5.3</b> OLS estimator of the regression coefficients</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#s:penguins-mlr"><i class="fa fa-check"></i><b>3.6</b> Penguins multiple linear regression example</a></li>
<li class="chapter" data-level="3.7" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#model-types"><i class="fa fa-check"></i><b>3.7</b> Types of linear models</a></li>
<li class="chapter" data-level="3.8" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#categorical-predictors"><i class="fa fa-check"></i><b>3.8</b> Categorical predictors</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#indicator-variables"><i class="fa fa-check"></i><b>3.8.1</b> Indicator variables</a></li>
<li class="chapter" data-level="3.8.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#parallel-and-separate-lines-models"><i class="fa fa-check"></i><b>3.8.2</b> Parallel and separate lines models</a></li>
<li class="chapter" data-level="3.8.3" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#extensions"><i class="fa fa-check"></i><b>3.8.3</b> Extensions</a></li>
<li class="chapter" data-level="3.8.4" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#avoiding-an-easy-mistake"><i class="fa fa-check"></i><b>3.8.4</b> Avoiding an easy mistake</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#s:penguins-mlr2"><i class="fa fa-check"></i><b>3.9</b> Penguins example with categorical predictor</a></li>
<li class="chapter" data-level="3.10" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#evaluating-model-fit"><i class="fa fa-check"></i><b>3.10</b> Evaluating model fit</a></li>
<li class="chapter" data-level="3.11" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#summary"><i class="fa fa-check"></i><b>3.11</b> Summary</a>
<ul>
<li class="chapter" data-level="3.11.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ss:term-summary"><i class="fa fa-check"></i><b>3.11.1</b> Summary of terms</a></li>
<li class="chapter" data-level="3.11.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#summary-of-functions"><i class="fa fa-check"></i><b>3.11.2</b> Summary of functions</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#going-deeper"><i class="fa fa-check"></i><b>3.12</b> Going Deeper</a>
<ul>
<li class="chapter" data-level="3.12.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#degrees-of-freedom"><i class="fa fa-check"></i><b>3.12.1</b> Degrees of freedom</a></li>
<li class="chapter" data-level="3.12.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#slr-derivation"><i class="fa fa-check"></i><b>3.12.2</b> Derivation of the OLS estimators of the simple linear regression model coefficients</a></li>
<li class="chapter" data-level="3.12.3" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#unbiasedness-of-ols-estimators"><i class="fa fa-check"></i><b>3.12.3</b> Unbiasedness of OLS estimators</a></li>
<li class="chapter" data-level="3.12.4" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#manual-calculation-penguins-simple-linear-regression-example"><i class="fa fa-check"></i><b>3.12.4</b> Manual calculation Penguins simple linear regression example</a></li>
<li class="chapter" data-level="3.12.5" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#mlr-derivation"><i class="fa fa-check"></i><b>3.12.5</b> Derivation of the OLS estimator for the multiple linear regression model coefficients</a></li>
<li class="chapter" data-level="3.12.6" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#manual-calculation-of-penguins-multiple-linear-regression-example"><i class="fa fa-check"></i><b>3.12.6</b> Manual calculation of Penguins multiple linear regression example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="interp-chapter.html"><a href="interp-chapter.html"><i class="fa fa-check"></i><b>4</b> Interpreting a fitted linear model</a>
<ul>
<li class="chapter" data-level="4.1" data-path="interp-chapter.html"><a href="interp-chapter.html#interpretation-of-coefficients"><i class="fa fa-check"></i><b>4.1</b> Interpretation of coefficients</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="interp-chapter.html"><a href="interp-chapter.html#interpretation-for-simple-linear-regression"><i class="fa fa-check"></i><b>4.1.1</b> Interpretation for simple linear regression</a></li>
<li class="chapter" data-level="4.1.2" data-path="interp-chapter.html"><a href="interp-chapter.html#interp-1st-order-ml"><i class="fa fa-check"></i><b>4.1.2</b> Interpretation for first-order multiple linear regression models</a></li>
<li class="chapter" data-level="4.1.3" data-path="interp-chapter.html"><a href="interp-chapter.html#regressor-roles"><i class="fa fa-check"></i><b>4.1.3</b> Roles of regressor variables</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="interp-chapter.html"><a href="interp-chapter.html#effect-plots"><i class="fa fa-check"></i><b>4.2</b> Effect plots</a></li>
<li class="chapter" data-level="4.3" data-path="interp-chapter.html"><a href="interp-chapter.html#interp-cat-predictor"><i class="fa fa-check"></i><b>4.3</b> Interpretation for categorical predictors</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="interp-chapter.html"><a href="interp-chapter.html#pl-interp"><i class="fa fa-check"></i><b>4.3.1</b> Coefficient interpretation for parallel lines models</a></li>
<li class="chapter" data-level="4.3.2" data-path="interp-chapter.html"><a href="interp-chapter.html#effect-plots-for-fitted-models-with-non-interacting-categorical-predictors"><i class="fa fa-check"></i><b>4.3.2</b> Effect plots for fitted models with non-interacting categorical predictors</a></li>
<li class="chapter" data-level="4.3.3" data-path="interp-chapter.html"><a href="interp-chapter.html#sl-interp"><i class="fa fa-check"></i><b>4.3.3</b> Coefficient interpretation for separate lines models</a></li>
<li class="chapter" data-level="4.3.4" data-path="interp-chapter.html"><a href="interp-chapter.html#effect-plots-for-interacting-categorical-predictors"><i class="fa fa-check"></i><b>4.3.4</b> Effect plots for interacting categorical predictors</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="interp-chapter.html"><a href="interp-chapter.html#added-variable-and-leverage-plots"><i class="fa fa-check"></i><b>4.4</b> Added-variable and leverage plots</a></li>
<li class="chapter" data-level="4.5" data-path="interp-chapter.html"><a href="interp-chapter.html#going-deeper-1"><i class="fa fa-check"></i><b>4.5</b> Going deeper</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="interp-chapter.html"><a href="interp-chapter.html#orthogonality"><i class="fa fa-check"></i><b>4.5.1</b> Orthogonality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="linear-model-theory.html"><a href="linear-model-theory.html"><i class="fa fa-check"></i><b>5</b> Basic theoretical results for linear models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="linear-model-theory.html"><a href="linear-model-theory.html#standard-assumptions"><i class="fa fa-check"></i><b>5.1</b> Standard assumptions</a></li>
<li class="chapter" data-level="5.2" data-path="linear-model-theory.html"><a href="linear-model-theory.html#summary-of-results"><i class="fa fa-check"></i><b>5.2</b> Summary of results</a></li>
<li class="chapter" data-level="5.3" data-path="linear-model-theory.html"><a href="linear-model-theory.html#results-for-mathbfy"><i class="fa fa-check"></i><b>5.3</b> Results for <span class="math inline">\(\mathbf{y}\)</span></a></li>
<li class="chapter" data-level="5.4" data-path="linear-model-theory.html"><a href="linear-model-theory.html#results-for-hatboldsymbolbeta"><i class="fa fa-check"></i><b>5.4</b> Results for <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span></a></li>
<li class="chapter" data-level="5.5" data-path="linear-model-theory.html"><a href="linear-model-theory.html#results-for-the-residuals"><i class="fa fa-check"></i><b>5.5</b> Results for the residuals</a></li>
<li class="chapter" data-level="5.6" data-path="linear-model-theory.html"><a href="linear-model-theory.html#the-gauss-markov-theorem"><i class="fa fa-check"></i><b>5.6</b> The Gauss-Markov Theorem</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>6</b> Linear model inference and prediction</a>
<ul>
<li class="chapter" data-level="6.1" data-path="inference.html"><a href="inference.html#overview-of-inference-and-prediction"><i class="fa fa-check"></i><b>6.1</b> Overview of inference and prediction</a></li>
<li class="chapter" data-level="6.2" data-path="inference.html"><a href="inference.html#necessary-notation"><i class="fa fa-check"></i><b>6.2</b> Necessary notation</a></li>
<li class="chapter" data-level="6.3" data-path="inference.html"><a href="inference.html#properties-betahat"><i class="fa fa-check"></i><b>6.3</b> Properties of the OLS estimator</a></li>
<li class="chapter" data-level="6.4" data-path="inference.html"><a href="inference.html#parametric-confidence-intervals-for-regression-coefficients"><i class="fa fa-check"></i><b>6.4</b> Parametric confidence intervals for regression coefficients</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="inference.html"><a href="inference.html#tci"><i class="fa fa-check"></i><b>6.4.1</b> Standard <span class="math inline">\(t\)</span>-based confidence intervals</a></li>
<li class="chapter" data-level="6.4.2" data-path="inference.html"><a href="inference.html#mcp"><i class="fa fa-check"></i><b>6.4.2</b> The multiple comparisons problem</a></li>
<li class="chapter" data-level="6.4.3" data-path="inference.html"><a href="inference.html#adjusted-cis-betas"><i class="fa fa-check"></i><b>6.4.3</b> Adjusted confidence intervals for regression coefficients</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="inference.html"><a href="inference.html#prediction-mean-response-versus-new-response"><i class="fa fa-check"></i><b>6.5</b> Prediction: mean response versus new response</a></li>
<li class="chapter" data-level="6.6" data-path="inference.html"><a href="inference.html#parametric-ci-mean-response"><i class="fa fa-check"></i><b>6.6</b> Parametric confidence interval for the mean response</a></li>
<li class="chapter" data-level="6.7" data-path="inference.html"><a href="inference.html#pi-new-response"><i class="fa fa-check"></i><b>6.7</b> Parametric prediction interval for a new response</a></li>
<li class="chapter" data-level="6.8" data-path="inference.html"><a href="inference.html#parametric-hypothesis-test-for-a-single-regression-coefficient"><i class="fa fa-check"></i><b>6.8</b> Parametric hypothesis test for a single regression coefficient</a></li>
<li class="chapter" data-level="6.9" data-path="inference.html"><a href="inference.html#going-deeper-2"><i class="fa fa-check"></i><b>6.9</b> Going deeper</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="inference.html"><a href="inference.html#manual-t-cis"><i class="fa fa-check"></i><b>6.9.1</b> Manual calculation of the standard <span class="math inline">\(t\)</span>-based confidence interval for a regression coefficient</a></li>
<li class="chapter" data-level="6.9.2" data-path="inference.html"><a href="inference.html#mean-response-calculations"><i class="fa fa-check"></i><b>6.9.2</b> Details about estimation of the mean response</a></li>
<li class="chapter" data-level="6.9.3" data-path="inference.html"><a href="inference.html#manual-calc-ci-mean-response"><i class="fa fa-check"></i><b>6.9.3</b> Manual calculation of confidence intervals for the mean response</a></li>
<li class="chapter" data-level="6.9.4" data-path="inference.html"><a href="inference.html#new-response-pi-calculations"><i class="fa fa-check"></i><b>6.9.4</b> Details about prediction interval for a new response</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html"><i class="fa fa-check"></i><b>A</b> Overview of matrix facts</a>
<ul>
<li class="chapter" data-level="A.1" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#notation"><i class="fa fa-check"></i><b>A.1</b> Notation</a></li>
<li class="chapter" data-level="A.2" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#basic-mathematical-operations"><i class="fa fa-check"></i><b>A.2</b> Basic mathematical operations</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#addition-and-subtraction"><i class="fa fa-check"></i><b>A.2.1</b> Addition and subtraction</a></li>
<li class="chapter" data-level="A.2.2" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#scalar-multiplication"><i class="fa fa-check"></i><b>A.2.2</b> Scalar multiplication</a></li>
<li class="chapter" data-level="A.2.3" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#matrix-multiplication"><i class="fa fa-check"></i><b>A.2.3</b> Matrix multiplication</a></li>
<li class="chapter" data-level="A.2.4" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#transpose"><i class="fa fa-check"></i><b>A.2.4</b> Transpose</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#basic-mathematical-properties"><i class="fa fa-check"></i><b>A.3</b> Basic mathematical properties</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#associative-property"><i class="fa fa-check"></i><b>A.3.1</b> Associative property</a></li>
<li class="chapter" data-level="A.3.2" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#distributive-property"><i class="fa fa-check"></i><b>A.3.2</b> Distributive property</a></li>
<li class="chapter" data-level="A.3.3" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#no-commutative-property"><i class="fa fa-check"></i><b>A.3.3</b> No commutative property</a></li>
<li class="chapter" data-level="A.3.4" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#transpose-related-properties"><i class="fa fa-check"></i><b>A.3.4</b> Transpose-related properties</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#special-matrices"><i class="fa fa-check"></i><b>A.4</b> Special matrices</a>
<ul>
<li class="chapter" data-level="A.4.1" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#square-matrices"><i class="fa fa-check"></i><b>A.4.1</b> Square matrices</a></li>
<li class="chapter" data-level="A.4.2" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#identity-matrix"><i class="fa fa-check"></i><b>A.4.2</b> Identity matrix</a></li>
<li class="chapter" data-level="A.4.3" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#diagonal-matrices"><i class="fa fa-check"></i><b>A.4.3</b> Diagonal matrices</a></li>
<li class="chapter" data-level="A.4.4" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#symmetric-matrices"><i class="fa fa-check"></i><b>A.4.4</b> Symmetric matrices</a></li>
<li class="chapter" data-level="A.4.5" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#idempotent-matrices"><i class="fa fa-check"></i><b>A.4.5</b> Idempotent matrices</a></li>
<li class="chapter" data-level="A.4.6" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#positive-definite-matrices"><i class="fa fa-check"></i><b>A.4.6</b> Positive definite matrices</a></li>
<li class="chapter" data-level="A.4.7" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#inverse-matrix"><i class="fa fa-check"></i><b>A.4.7</b> Inverse matrix</a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#matrix-derivatives"><i class="fa fa-check"></i><b>A.5</b> Matrix derivatives</a></li>
<li class="chapter" data-level="A.6" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#additional-topics"><i class="fa fa-check"></i><b>A.6</b> Additional topics</a>
<ul>
<li class="chapter" data-level="A.6.1" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#determinant"><i class="fa fa-check"></i><b>A.6.1</b> Determinant</a></li>
<li class="chapter" data-level="A.6.2" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#linearly-independent-vectors"><i class="fa fa-check"></i><b>A.6.2</b> Linearly independent vectors</a></li>
<li class="chapter" data-level="A.6.3" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#rank"><i class="fa fa-check"></i><b>A.6.3</b> Rank</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="prob-review.html"><a href="prob-review.html"><i class="fa fa-check"></i><b>B</b> Overview of probability, random variables, and random vectors</a>
<ul>
<li class="chapter" data-level="B.1" data-path="prob-review.html"><a href="prob-review.html#probability-basics"><i class="fa fa-check"></i><b>B.1</b> Probability Basics</a></li>
<li class="chapter" data-level="B.2" data-path="prob-review.html"><a href="prob-review.html#random-variables"><i class="fa fa-check"></i><b>B.2</b> Random Variables</a>
<ul>
<li class="chapter" data-level="B.2.1" data-path="prob-review.html"><a href="prob-review.html#discrete-random-variables"><i class="fa fa-check"></i><b>B.2.1</b> Discrete random variables</a></li>
<li class="chapter" data-level="B.2.2" data-path="prob-review.html"><a href="prob-review.html#continuous-random-variables"><i class="fa fa-check"></i><b>B.2.2</b> Continuous random variables</a></li>
<li class="chapter" data-level="B.2.3" data-path="prob-review.html"><a href="prob-review.html#useful-facts-for-transformations-of-random-variables"><i class="fa fa-check"></i><b>B.2.3</b> Useful facts for transformations of random variables</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="prob-review.html"><a href="prob-review.html#multivariate-distributions"><i class="fa fa-check"></i><b>B.3</b> Multivariate distributions</a>
<ul>
<li class="chapter" data-level="B.3.1" data-path="prob-review.html"><a href="prob-review.html#basic-properties"><i class="fa fa-check"></i><b>B.3.1</b> Basic properties</a></li>
<li class="chapter" data-level="B.3.2" data-path="prob-review.html"><a href="prob-review.html#marginal-distributions"><i class="fa fa-check"></i><b>B.3.2</b> Marginal distributions</a></li>
<li class="chapter" data-level="B.3.3" data-path="prob-review.html"><a href="prob-review.html#independence-of-random-variables"><i class="fa fa-check"></i><b>B.3.3</b> Independence of random variables</a></li>
<li class="chapter" data-level="B.3.4" data-path="prob-review.html"><a href="prob-review.html#conditional-distributions"><i class="fa fa-check"></i><b>B.3.4</b> Conditional distributions</a></li>
<li class="chapter" data-level="B.3.5" data-path="prob-review.html"><a href="prob-review.html#covariance"><i class="fa fa-check"></i><b>B.3.5</b> Covariance</a></li>
<li class="chapter" data-level="B.3.6" data-path="prob-review.html"><a href="prob-review.html#useful-facts-for-transformations-of-multiple-random-variables"><i class="fa fa-check"></i><b>B.3.6</b> Useful facts for transformations of multiple random variables</a></li>
<li class="chapter" data-level="B.3.7" data-path="prob-review.html"><a href="prob-review.html#binomial-distribution-example"><i class="fa fa-check"></i><b>B.3.7</b> Binomial distribution example</a></li>
<li class="chapter" data-level="B.3.8" data-path="prob-review.html"><a href="prob-review.html#continuous-bivariate-distribution-example"><i class="fa fa-check"></i><b>B.3.8</b> Continuous bivariate distribution example</a></li>
</ul></li>
<li class="chapter" data-level="B.4" data-path="prob-review.html"><a href="prob-review.html#random-vectors"><i class="fa fa-check"></i><b>B.4</b> Random vectors</a>
<ul>
<li class="chapter" data-level="B.4.1" data-path="prob-review.html"><a href="prob-review.html#definition"><i class="fa fa-check"></i><b>B.4.1</b> Definition</a></li>
<li class="chapter" data-level="B.4.2" data-path="prob-review.html"><a href="prob-review.html#mean-variance-and-covariance"><i class="fa fa-check"></i><b>B.4.2</b> Mean, variance, and covariance</a></li>
<li class="chapter" data-level="B.4.3" data-path="prob-review.html"><a href="prob-review.html#properties-of-transformations-of-random-vectors"><i class="fa fa-check"></i><b>B.4.3</b> Properties of transformations of random vectors</a></li>
<li class="chapter" data-level="B.4.4" data-path="prob-review.html"><a href="prob-review.html#continuous-bivariate-distribution-example-continued"><i class="fa fa-check"></i><b>B.4.4</b> Continuous bivariate distribution example continued</a></li>
</ul></li>
<li class="chapter" data-level="B.5" data-path="prob-review.html"><a href="prob-review.html#multivariate-normal-gaussian-distribution"><i class="fa fa-check"></i><b>B.5</b> Multivariate normal (Gaussian) distribution</a>
<ul>
<li class="chapter" data-level="B.5.1" data-path="prob-review.html"><a href="prob-review.html#definition-1"><i class="fa fa-check"></i><b>B.5.1</b> Definition</a></li>
<li class="chapter" data-level="B.5.2" data-path="prob-review.html"><a href="prob-review.html#linear-functions-of-a-multivariate-normal-random-vector"><i class="fa fa-check"></i><b>B.5.2</b> Linear functions of a multivariate normal random vector</a></li>
<li class="chapter" data-level="B.5.3" data-path="prob-review.html"><a href="prob-review.html#ols-example"><i class="fa fa-check"></i><b>B.5.3</b> OLS example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="est-infer-review.html"><a href="est-infer-review.html"><i class="fa fa-check"></i><b>C</b> Review of Estimation and Inference</a>
<ul>
<li class="chapter" data-level="C.1" data-path="est-infer-review.html"><a href="est-infer-review.html#estimation"><i class="fa fa-check"></i><b>C.1</b> Estimation</a></li>
<li class="chapter" data-level="C.2" data-path="est-infer-review.html"><a href="est-infer-review.html#hypothesis-testing"><i class="fa fa-check"></i><b>C.2</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="C.3" data-path="est-infer-review.html"><a href="est-infer-review.html#confidence-intervals"><i class="fa fa-check"></i><b>C.3</b> Confidence Intervals</a></li>
<li class="chapter" data-level="C.4" data-path="est-infer-review.html"><a href="est-infer-review.html#linking-hypothesis-tests-and-confidence-intervals"><i class="fa fa-check"></i><b>C.4</b> Linking Hypothesis Tests and Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Progressive Introduction to Linear Models</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="est-infer-review" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">C</span> Review of Estimation and Inference<a href="est-infer-review.html#est-infer-review" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>A primary purpose of statistics is taking a sample of values from a population and using the sample to draw conclusions about that population. In what follows, we discuss statistical concepts related to estimation, hypothesis testing, and confidence intervals.</p>
<div id="estimation" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">C.1</span> Estimation<a href="est-infer-review.html#estimation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A <strong>parameter</strong> is a numeric characteristic that describes a population. E.g., the population mean, standard deviation, or cumulative distribution function.</p>
<p>The <strong>target</strong> parameter or <strong>parameter of interest</strong> is the population parameter we would like to estimate.</p>
<p>There are different kinds of estimates:</p>
<ul>
<li>A <strong>point estimate</strong> is a single number that we <em>hope</em> is close to the true value of the target parameter.</li>
<li>An <strong>interval estimate</strong> is an interval of numbers that we <em>hope</em> will contain the target parameter.</li>
</ul>
<p>An estimate and an estimator are different but related concepts.</p>
<ul>
<li>An estimate is a specific number (for a point estimate) or a specific range of numbers (for an interval estimate).</li>
<li>An <strong>estimator</strong> is a formula we use to calculate an estimate (once we get a sample of data).</li>
</ul>
<p>Once the data are observed, an estimate is fixed. An estimator is a random variable. An estimator produces different estimates based on the sample of data we obtain from the population.</p>
<p>The <strong>sampling distribution</strong> of an estimator is the distribution of the estimates we get when we use the estimator to compute estimates from all possible samples of a fixed size <span class="math inline">\(n\)</span> from the population of interest.</p>
<p>A point estimator, <span class="math inline">\(\hat{\theta}\)</span>, is an <strong>unbiased estimator</strong> of a target parameter, <span class="math inline">\(\theta\)</span>, if <span class="math inline">\(E(\hat{\theta})=\theta\)</span>. An estimator is biased if it is not biased.</p>
<p>The <strong>bias</strong> of an estimator is defined as
<span class="math display">\[
B(\hat{\theta})=E(\hat{\theta})-\theta.
\]</span></p>
<p>The <strong>variance of an estimator</strong> is defined as
<span class="math display">\[
\mathrm{var}(\hat{\theta})=E[\hat{\theta}-E(\hat{\theta})]^2.
\]</span>
The <strong>standard error of an estimator</strong> is the standard deviation of the estimator, i.e.,
<span class="math display">\[
\mathrm{se}(\hat{\theta})\equiv\mathrm{sd}(\hat{\theta})=\sqrt{\mathrm{var}(\hat{\theta})}.
\]</span>
Typically, we cannot compute the standard error of an estimator because it is a function of parameters that we do not know. Instead, we use the sample data to estimate the standard error. When we hear or read the term “standard error”, we must carefully evaluate whether the “standard error” presented is the theoretical standard error or the estimated standard error (and it’s nearly always the latter).</p>
<p>The <strong>mean square error</strong> of a point estimator is
<span class="math display">\[
MSE(\hat{\theta})=E(\hat{\theta}-\theta)^{2},
\]</span>
which is equivalent to
<span class="math display">\[
MSE(\hat{\theta})=\mathrm{var}(\hat{\theta})+[B(\hat{\theta})]^{2}.
\]</span></p>
<p>The MSE formula makes it clear that there is a “bias-variance trade off” when choosing between point estimators. Typically, unbiased point estimators will have larger variance (and correspondingly, MSE). Biased estimators will often have smaller MSE, but are (obviously) biased. It’s a trade off we have to balance.</p>
</div>
<div id="hypothesis-testing" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">C.2</span> Hypothesis Testing<a href="est-infer-review.html#hypothesis-testing" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A <strong>statistical test of hypotheses</strong> or <strong>hypothesis test</strong> is a
statistical procedure used to decide between a null hypothesis, <span class="math inline">\(H_0\)</span>, and an alternative hypothesis, <span class="math inline">\(H_a\)</span> or <span class="math inline">\(H_1\)</span>. The null hypothesis is usually a hypothesis that “nothing interesting is going on”. The alternative hypothesis is generally the complement of the null hypothesis and is usually what we want to show is true.</p>
<p>A <strong>test statistic</strong> is a number used to decide between <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_a\)</span>. A test statistic is a function of the data, and generally, parameters in the hypotheses. A test statistic measures the compatibility of the observed data with <span class="math inline">\(H_0\)</span>. A “small” test statistic suggests the observed data are consistent with <span class="math inline">\(H_0\)</span>, while an “extreme” test statistic indicates that the observed data are inconsistent with <span class="math inline">\(H_0\)</span>, which we take as evidence that <span class="math inline">\(H_a\)</span> is true.</p>
<p>The <strong>null distribution</strong> allows us to identify the values of the test statistic that are typical or unusual when <span class="math inline">\(H_0\)</span> is true. Formally, the null distribution is the distribution of the test statistic under the assumption that <span class="math inline">\(H_0\)</span> is true.</p>
<p>There are two types of errors we can make when doing hypothesis testing:</p>
<ul>
<li>Type I error: rejecting <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_0\)</span> is true.</li>
<li>Type II error: failing to reject <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_a\)</span> is true.</li>
</ul>
<p>We can control the Type I error rate at a specified level, <span class="math inline">\(\alpha\)</span>, called the <strong>significance level</strong>, since we know the distribution of our test statistic under the assumption that <span class="math inline">\(H_0\)</span> is true. We reject <span class="math inline">\(H_0\)</span> and conclude that <span class="math inline">\(H_a\)</span> is true if the test statistic falls in the <strong>rejection region</strong> of the null distribution, which is the set of test statistics that are the <span class="math inline">\(100\alpha\%\)</span> most unlikely test statistics if <span class="math inline">\(H_0\)</span> is true.</p>
<p>Instead of using the test statistic directly to decide between <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_a\)</span>, we generally use the test statistic to compute a p-value. The <strong>p-value</strong> of a test statistic is the probability of seeing a test statistic at least as supportive of <span class="math inline">\(H_a\)</span> when <span class="math inline">\(H_0\)</span> is true. If we specify the significance level, <span class="math inline">\(\alpha\)</span>, prior to performing our hypothesis test (which is the ethical thing to do), then we reject <span class="math inline">\(H_0\)</span> and conclude <span class="math inline">\(H_a\)</span> is true when the p-value <span class="math inline">\(&lt;\alpha\)</span>. Otherwise, we fail to reject <span class="math inline">\(H_0\)</span>.</p>
<p>Researchers sometimes say that the smaller the p-value, the stronger the
evidence that <span class="math inline">\(H_a\)</span> is true and <span class="math inline">\(H_0\)</span> is false. This isn’t definitively
true because the p-value doesn’t have the ability to distinguish between the following options: (1) <span class="math inline">\(H_0\)</span> is true but our observed data were very unlikely, (2) <span class="math inline">\(H_0\)</span> is
false. When <span class="math inline">\(H_0\)</span> is true, then the test statistic (for simple hypotheses and continuous test statistics) has a uniform distribution over the interval [0, 1]. However, if the <span class="math inline">\(H_a\)</span> is true, then the p-value is more
likely to be small, which makes us think <span class="math inline">\(H_a\)</span> is true for small
p-values. However, unless we know the <strong>power</strong> of our test, which is
the probability that we reject <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_a\)</span> is true, then it is very
difficult to assess how much evidence for <span class="math inline">\(H_a\)</span> a small p-value
provides. <span class="citation">Gibson (<a href="#ref-gibson_pvalue" role="doc-biblioref">2021</a>)</span> point out the p-values can be
interpreted naturally on a <span class="math inline">\(\log_{10}\)</span> scale. <span class="citation">Gibson (<a href="#ref-gibson_pvalue" role="doc-biblioref">2021</a>)</span> states:</p>
<blockquote>
<p>The p-value can be expressed as <span class="math inline">\(p=c\times 10^{-k}\)</span> so that
<span class="math inline">\(\log_{10}(p)=-\log_{10}(c)+k\)</span>, where <span class="math inline">\(c\)</span> is a constant and <span class="math inline">\(k\)</span> is an
integer, which implies that only the magnitude <em>k</em> measures the actual
strength of evidence <span class="citation">(<a href="#ref-boos_stefanski_2011_pvalues" role="doc-biblioref">Boos and Stefanski 2011</a>)</span>. <span class="math inline">\(\ldots\)</span> This
would suggest that <span class="math inline">\(p=0.01\)</span> (<span class="math inline">\(k=2\)</span>) could be interpreted as twice the
evidence [for <span class="math inline">\(H_a\)</span> as] <span class="math inline">\(p=0.10\)</span> (<span class="math inline">\(k=1\)</span>).</p>
</blockquote>
<p><span class="citation">Gibson (<a href="#ref-gibson_pvalue" role="doc-biblioref">2021</a>)</span> provides a thorough review of p-value interpretation.
Table <a href="est-infer-review.html#tab:pvalue-interp">C.1</a> summarizes common strength of evidence
interpretations for p-values.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:pvalue-interp">Table C.1: </span>An summary of common strength-of-evidence interpretations for p-values.
</caption>
<thead>
<tr>
<th style="text-align:left;">
p-value
</th>
<th style="text-align:left;">
Interpretation
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
more than -
<span class="math inline">\(0.10\)</span>
</td>
<td style="text-align:left;width: 3in; ">
no evidence for <span class="math inline">\(H_a\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\leq 0.10\)</span>
</td>
<td style="text-align:left;width: 3in; ">
weak evidence for <span class="math inline">\(H_a\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\leq 0.05\)</span>
</td>
<td style="text-align:left;width: 3in; ">
moderate evidence for <span class="math inline">\(H_a\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\leq 0.01\)</span>
</td>
<td style="text-align:left;width: 3in; ">
strong evidence for <span class="math inline">\(H_a\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\leq 0.001\)</span>
</td>
<td style="text-align:left;width: 3in; ">
very strong evidence for <span class="math inline">\(H_a\)</span>
</td>
</tr>
</tbody>
</table>
<p><strong>Example</strong></p>
<p>Suppose that <span class="math inline">\(Y_1,\ldots,Y_n\)</span> is a random sample (in other words,
an independent and identically distributed sample) from a population having
a normal distribution with unknown mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2=1\)</span>.</p>
<p>We would like to decide between the following two hypotheses:
<span class="math inline">\(H_0:\mu=0\)</span> and <span class="math inline">\(H_a:\mu\neq 0\)</span>.</p>
<p>Consider the statistic <span class="math inline">\(\bar{Y} = \frac{1}{n} \sum_{i=1}^n Y_i\)</span>. If <span class="math inline">\(H_0\)</span> is true, then <span class="math inline">\(\bar{Y} \sim \mathcal{N}(0,1/n)\)</span> and the test statistic
<span class="math display">\[
Z^*=\bar{Y}/(1/\sqrt{n})=\sqrt{n}\bar{Y}\sim \mathcal{N}(0, 1),
\]</span></p>
<p>i.e., the null distribution of <span class="math inline">\(Z^*\)</span> is <span class="math inline">\(\mathcal{N}(0,1)\)</span>.</p>
<p>If <span class="math inline">\(\alpha=0.10\)</span>, then the 10% of test statistics that are most unlikely if <span class="math inline">\(H_0\)</span>
is true (i.e., most supportive of <span class="math inline">\(H_a\)</span>) are more extreme than <span class="math inline">\(Z^{0.95}\)</span> and <span class="math inline">\(Z^{0.05}\)</span>, the 0.05 and 0.95 quantiles of a standard
normal distribution, respectively. (The superscript in the quantile notation indicates the area to the right of the quantile in the CDF). The 0.05 quantile of the standard normal distribution is -1.65 and the 0.95 quantile is 1.65. In R, we can find these quantile using the <code>qnorm</code> function, where the first argument of <code>qnorm</code> is <code>p</code>, which is the vector of probabilities to the LEFT of the quantile. We verify these quantiles using the code below.</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="est-infer-review.html#cb178-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fu">c</span>(<span class="fl">0.05</span>,<span class="fl">0.95</span>))</span>
<span id="cb178-2"><a href="est-infer-review.html#cb178-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] -1.644854  1.644854</span></span></code></pre></div>
<p><span class="math inline">\(H_0\)</span> should be rejected when <span class="math inline">\(Z^*\)</span> is less than -1.65 or more than
1.65, i.e., the rejection region is <span class="math inline">\((-\infty, -1.65)\cup(1.65,\infty)\)</span>.</p>
<p>Alternatively, we could compute the p-value using the formula
<span class="math inline">\(2P(Z\geq |Z^*|)\)</span> in order to make our choice between the hypotheses.</p>
<p>Suppose <span class="math inline">\(z^*=1.74\)</span> and <span class="math inline">\(\alpha=0.10\)</span>. The test statistic is in the rejection region, so we would conclude that <span class="math inline">\(H_a\)</span>
is true. The p-value is <span class="math inline">\(2P(Z\geq 1.74)=0.082\)</span>. Using the p-value approach we would conclude that <span class="math inline">\(H_a\)</span> is true. (Note that the rejection region and p-value approaches to deciding between hypotheses must agree). In R, we can compute the p-value using the code below.</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="est-infer-review.html#cb179-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span>(<span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fl">1.74</span>))</span>
<span id="cb179-2"><a href="est-infer-review.html#cb179-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.08185902</span></span></code></pre></div>
<p>In straightforward language, our interpretation could be: there is weak evidence that the population mean differs from 0.</p>
<p><strong>Simulation study</strong></p>
<p>We provide a brief simulation study to better understand the null distribution and also how rejection regions are chosen to control the type I error rate.</p>
<p>Assume that we sample <span class="math inline">\(n=10\)</span> values from a <span class="math inline">\(\mathcal{N}(\mu, \sigma^2)\)</span> population but that we don’t know the mean or the standard deviation. Assume the hypotheses we want to test are <span class="math inline">\(H_0: \mu = 2\)</span> versus <span class="math inline">\(H_a: \mu &gt; 2\)</span> (implicitly, the null hypothesis is <span class="math inline">\(H_0: \mu \leq 2\)</span>).</p>
<p>In this context, it is common to use the test statistic
<span class="math display">\[
T^* = \frac{\bar{Y} - \mu}{s/\sqrt{n}},
\]</span>
where <span class="math inline">\(s\)</span> is the sample standard deviation of the measurements. Under the null hypothesis, <span class="math inline">\(\mu=2\)</span>, and statistical theory tells us that <span class="math inline">\(T^* \sim t_{n-1}\)</span>, i.e., the test statistic has a <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(n-1\)</span> degrees of freedom. Since <span class="math inline">\(n=10\)</span>, our test statistic has a <span class="math inline">\(t\)</span> distribution with 9 degrees of freedom if the null hypothesis is true.</p>
<p>Recall that the null distribution of a test statistic is its sampling distribution under the assumption that the null hypothesis is true. In the code below, we:</p>
<ol style="list-style-type: decimal">
<li>Draw <span class="math inline">\(B=1,000\)</span> samples of size <span class="math inline">\(n=10\)</span> from our <span class="math inline">\(\mathcal{N}(\mu,\sigma^2)\)</span> population assuming the null hypothesis is true, i.e., with <span class="math inline">\(\mu = 2\)</span>.</li>
<li>Compute the test statistic for each sample.</li>
</ol>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="est-infer-review.html#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="co"># set number seed for reproducible results</span></span>
<span id="cb180-2"><a href="est-infer-review.html#cb180-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12</span>)</span>
<span id="cb180-3"><a href="est-infer-review.html#cb180-3" aria-hidden="true" tabindex="-1"></a><span class="co"># create matrix to store samples</span></span>
<span id="cb180-4"><a href="est-infer-review.html#cb180-4" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">nrow =</span> <span class="dv">10000</span>, <span class="at">ncol =</span> <span class="dv">10</span>)</span>
<span id="cb180-5"><a href="est-infer-review.html#cb180-5" aria-hidden="true" tabindex="-1"></a><span class="co"># draw 10000 samples of size 10 from a N(4, 4^2)</span></span>
<span id="cb180-6"><a href="est-infer-review.html#cb180-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10000</span>) {</span>
<span id="cb180-7"><a href="est-infer-review.html#cb180-7" aria-hidden="true" tabindex="-1"></a>  samples[i,] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">10</span>, <span class="at">mean =</span> <span class="dv">2</span>, <span class="at">sd =</span> <span class="dv">4</span>)</span>
<span id="cb180-8"><a href="est-infer-review.html#cb180-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb180-9"><a href="est-infer-review.html#cb180-9" aria-hidden="true" tabindex="-1"></a><span class="co"># compute sample mean and sd for each sample</span></span>
<span id="cb180-10"><a href="est-infer-review.html#cb180-10" aria-hidden="true" tabindex="-1"></a>means <span class="ot">&lt;-</span>  <span class="fu">rowMeans</span>(samples)</span>
<span id="cb180-11"><a href="est-infer-review.html#cb180-11" aria-hidden="true" tabindex="-1"></a>sds <span class="ot">&lt;-</span> <span class="fu">apply</span>(samples, <span class="dv">1</span>, sd)</span>
<span id="cb180-12"><a href="est-infer-review.html#cb180-12" aria-hidden="true" tabindex="-1"></a><span class="co"># compute test statistic for each sample</span></span>
<span id="cb180-13"><a href="est-infer-review.html#cb180-13" aria-hidden="true" tabindex="-1"></a>tstats <span class="ot">&lt;-</span> (means <span class="sc">-</span> <span class="dv">2</span>)<span class="sc">/</span>(sds<span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">10</span>))</span></code></pre></div>
<p>We now use the code below to compute the empirical density of the computed test statistics and overlay a density for a <span class="math inline">\(t\)</span> random variable with 9 degrees of freedom.</p>
<p>To draw our sample, we must choose a value of <span class="math inline">\(\sigma^2\)</span>. We will use <span class="math inline">\(\sigma^2 = 16\)</span>. The exact value isn’t important, but choosing a fixed number for <span class="math inline">\(\sigma^2\)</span> is critical for the example below. Figure <a href="est-infer-review.html#fig:tnullfigure">C.1</a> displays the results. We see that the two distributions match up very well.</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="est-infer-review.html#cb181-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot empirical null distribution</span></span>
<span id="cb181-2"><a href="est-infer-review.html#cb181-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">density</span>(tstats),</span>
<span id="cb181-3"><a href="est-infer-review.html#cb181-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;test statistic&quot;</span>,</span>
<span id="cb181-4"><a href="est-infer-review.html#cb181-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;density&quot;</span>,</span>
<span id="cb181-5"><a href="est-infer-review.html#cb181-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;empirical versus true null distribution&quot;</span>)</span>
<span id="cb181-6"><a href="est-infer-review.html#cb181-6" aria-hidden="true" tabindex="-1"></a><span class="co"># sequence to plot null density over</span></span>
<span id="cb181-7"><a href="est-infer-review.html#cb181-7" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="at">len =</span> <span class="dv">1000</span>)</span>
<span id="cb181-8"><a href="est-infer-review.html#cb181-8" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(s, <span class="fu">dt</span>(s, <span class="at">df =</span> <span class="dv">9</span>), <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:tnullfigure"></span>
<img src="A-Progessive-Introduction-to-Linear-Models_files/figure-html/tnullfigure-1.png" alt="Comparison of empirical null distribution to theoretical null distribution. The empirical null distribution is shown by the solid black line and the theoretical null distribution by a dashed blue line." width="672" />
<p class="caption">
Figure C.1: Comparison of empirical null distribution to theoretical null distribution. The empirical null distribution is shown by the solid black line and the theoretical null distribution by a dashed blue line.
</p>
</div>
<p>What should we takeaway from this example? The null distribution of a hypothesis test is the sampling distribution of the test statistic under the assumption that <span class="math inline">\(H_0\)</span> is true. We approximated the null distribution of our test statistic by drawing 10,000 samples from the population distribution under the assumption that <span class="math inline">\(H_0\)</span> was true.</p>
<p>How does the null distribution relate to choosing the rejection region? First, the type I error rate is the probability of rejecting <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_0\)</span> is true. Since we know the null distribution, we know what behavior to expect from our test statistic if <span class="math inline">\(H_0\)</span> is true. Thus, we know what test statistics are most unlikely if <span class="math inline">\(H_0\)</span> is true. Let’s say we want to control the type I error at <span class="math inline">\(\alpha = 0.05\)</span>. For this upper-tailed test, we should reject <span class="math inline">\(H_0\)</span> when the test statistic is greater than <span class="math inline">\(t^{0.05}_9\)</span>, i.e., the 0.95 quantile of a <span class="math inline">\(t\)</span> distribution with 9 degrees of freedom. Why do we use this threshold? Because if <span class="math inline">\(H_0\)</span> is true, this will only lead to erroneous rejections of <span class="math inline">\(H_0\)</span> (i.e., a type I error) 5% of the time. In the code below, we compute the sample proportion of test statistics from our null distribution that are more than <span class="math inline">\(t^{0.05}_9\)</span>. Our sample proportion is very close to 0.05, and this number will converge to 0.05 as we increase the number samples used in our simulation.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="est-infer-review.html#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(tstats <span class="sc">&gt;</span> <span class="fu">qt</span>(<span class="fl">0.95</span>, <span class="at">df =</span> <span class="dv">9</span>))</span>
<span id="cb182-2"><a href="est-infer-review.html#cb182-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.0489</span></span></code></pre></div>
</div>
<div id="confidence-intervals" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">C.3</span> Confidence Intervals<a href="est-infer-review.html#confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A <strong>confidence interval</strong> provides us with plausible values of a target parameter. It is the most common type of interval estimator.</p>
<p>A confidence interval procedure has an associated <strong>confidence level</strong>. When independent random samples are taken repeatedly from the population, a confidence interval procedure will produce intervals containing the target parameter with probability equal to the confidence level. Confidence level is associated with a confidence interval <em>procedure</em>, not a specific interval. A 95% confidence interval procedure will produce intervals that contain the target parameter 95% of the time. A specific interval estimate will either contain the target parameter or it will not.</p>
<p>The formulas for confidence intervals are usually derived from a pivotal quantity. A <strong>pivotal quantity</strong> is a function of the data and the target parameter whose distribution does not depend on the value of the target
parameter.</p>
<p><strong>Example:</strong></p>
<p>Suppose <span class="math inline">\(Y_1,Y_2,\ldots,Y_n \stackrel{i.i.d.}{\sim} \mathcal{N}(\mu, 1)\)</span>.</p>
<p>The random variable <span class="math inline">\(Z=(\bar{Y}-\mu)/(1/\sqrt{n})\sim \mathcal{N}(0,1)\)</span> is a pivotal quantity.</p>
<p>Since <span class="math inline">\(P(-1.96\leq Z\leq 1.96)=0.95\)</span>, we can derive that
<span class="math display">\[
P(\bar{Y}-1.96\times 1/\sqrt{n}\leq \mu \leq \bar{Y}+1.96\times 1/\sqrt{n})=0.95.
\]</span></p>
<p>Our 95% confidence interval for <span class="math inline">\(\mu\)</span> in this context is
<span class="math display">\[
[\bar{Y}-1.96\times 1/\sqrt{n}, \bar{Y}+1.96\times 1/\sqrt{n}].
\]</span>
If <span class="math inline">\(\bar{Y}=0.551\)</span> and <span class="math inline">\(n=10\)</span>, then the associated 95% confidence interval for <span class="math inline">\(\mu\)</span> is [-0.070,1.171].</p>
<p><strong>More discussion of confidence level</strong></p>
<p>The CI formula given above is supposed to produce 95% confidence intervals (i.e., the confidence level of the procedure is 0.95). If produce 100 intervals from independent data sets, then about 95% of them would contain the true mean, but about 5% would not. To illustrate this further, we use a small simulation example below to produce 100 95% confidence intervals using a sample of size n = 10 for a <span class="math inline">\(\mathcal{N(0,1)}\)</span> population.</p>
<p>First, we obtain 100 samples of size 10 from the population and then compute the sample mean of each sample. We do this in the code below.</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="est-infer-review.html#cb183-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create matrix to store samples</span></span>
<span id="cb183-2"><a href="est-infer-review.html#cb183-2" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> <span class="dv">100</span>, <span class="at">ncol =</span> <span class="dv">10</span>)</span>
<span id="cb183-3"><a href="est-infer-review.html#cb183-3" aria-hidden="true" tabindex="-1"></a><span class="co"># obtain 100 samples from the population</span></span>
<span id="cb183-4"><a href="est-infer-review.html#cb183-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>) {</span>
<span id="cb183-5"><a href="est-infer-review.html#cb183-5" aria-hidden="true" tabindex="-1"></a>  samples[i,] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">10</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb183-6"><a href="est-infer-review.html#cb183-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb183-7"><a href="est-infer-review.html#cb183-7" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the sample mean for each sample</span></span>
<span id="cb183-8"><a href="est-infer-review.html#cb183-8" aria-hidden="true" tabindex="-1"></a>means <span class="ot">=</span> <span class="fu">rowMeans</span>(samples) <span class="co">#calculates the mean of each row</span></span></code></pre></div>
<p>Next, we use the formula above to determine the lower and upper bound of the confidence interval associated with each interval. Since we want 95% confidence intervals, we use the 0.975 quantile of the standard normal distribution to construct our interval.</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="est-infer-review.html#cb184-1" aria-hidden="true" tabindex="-1"></a><span class="co">#calculate the lower and upper bounds for the 95% CIs</span></span>
<span id="cb184-2"><a href="est-infer-review.html#cb184-2" aria-hidden="true" tabindex="-1"></a>lb <span class="ot">=</span> means <span class="sc">-</span> <span class="fu">qnorm</span>(.<span class="dv">975</span>) <span class="sc">*</span> <span class="dv">1</span><span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">10</span>)</span>
<span id="cb184-3"><a href="est-infer-review.html#cb184-3" aria-hidden="true" tabindex="-1"></a>ub <span class="ot">=</span> means <span class="sc">+</span> <span class="fu">qnorm</span>(.<span class="dv">975</span>) <span class="sc">*</span> <span class="dv">1</span><span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">10</span>)</span></code></pre></div>
<p>Next, we plot each interval. The intervals are orange if the
interval doesn’t contain the true population mean, which is 0. Figure <a href="est-infer-review.html#fig:ci-interp-plot">C.2</a> displays our results.</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="est-infer-review.html#cb185-1" aria-hidden="true" tabindex="-1"></a><span class="co">#create blank plot</span></span>
<span id="cb185-2"><a href="est-infer-review.html#cb185-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">range</span>(<span class="fu">c</span>(lb, ub)), <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">100</span>),</span>
<span id="cb185-3"><a href="est-infer-review.html#cb185-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;interval&quot;</span>, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>)</span>
<span id="cb185-4"><a href="est-infer-review.html#cb185-4" aria-hidden="true" tabindex="-1"></a><span class="co"># title plot</span></span>
<span id="cb185-5"><a href="est-infer-review.html#cb185-5" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Interpretation of a Confidence Interval&quot;</span>)</span>
<span id="cb185-6"><a href="est-infer-review.html#cb185-6" aria-hidden="true" tabindex="-1"></a><span class="co"># plot true mean</span></span>
<span id="cb185-7"><a href="est-infer-review.html#cb185-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb185-8"><a href="est-infer-review.html#cb185-8" aria-hidden="true" tabindex="-1"></a><span class="co">#plot interval each sample</span></span>
<span id="cb185-9"><a href="est-infer-review.html#cb185-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>) <span class="fu">lines</span>(<span class="fu">c</span>(lb[i], ub[i]), <span class="fu">c</span>(i, i))</span>
<span id="cb185-10"><a href="est-infer-review.html#cb185-10" aria-hidden="true" tabindex="-1"></a><span class="co">#highlight intervals missing 0 in orange</span></span>
<span id="cb185-11"><a href="est-infer-review.html#cb185-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>) {</span>
<span id="cb185-12"><a href="est-infer-review.html#cb185-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (lb[i] <span class="sc">&gt;</span> <span class="dv">0</span> <span class="sc">|</span> ub[i] <span class="sc">&lt;</span> <span class="dv">0</span> )   {</span>
<span id="cb185-13"><a href="est-infer-review.html#cb185-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>(<span class="fu">c</span>(lb[i],ub[i]), <span class="fu">c</span>(i,i), <span class="at">col =</span> <span class="st">&quot;orange&quot;</span>)</span>
<span id="cb185-14"><a href="est-infer-review.html#cb185-14" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb185-15"><a href="est-infer-review.html#cb185-15" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:ci-interp-plot"></span>
<img src="A-Progessive-Introduction-to-Linear-Models_files/figure-html/ci-interp-plot-1.png" alt="A plot of 100 95% confidence intervals for a population mean produced from independent samples from a $\mathcal{N}(0,1)$ population." width="672" />
<p class="caption">
Figure C.2: A plot of 100 95% confidence intervals for a population mean produced from independent samples from a <span class="math inline">\(\mathcal{N}(0,1)\)</span> population.
</p>
</div>
<p>In this example, 96 out of 100 intervals for the population mean contained the true population mean of 0. Notice how the intervals move around. This is because each sample provides us with slightly different values, so the intervals move around because of the samples obtained. Each interval either contains the true mean of 0 or it does not. But as a whole, the procedure we are using will produce confidence intervals that contain the true mean 95% of the time.</p>
</div>
<div id="linking-hypothesis-tests-and-confidence-intervals" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">C.4</span> Linking Hypothesis Tests and Confidence Intervals<a href="est-infer-review.html#linking-hypothesis-tests-and-confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>CIs are directly linked to hypothesis tests.</p>
<p>A <span class="math inline">\(100(1-\alpha)\%\)</span> two-sided confidence interval for target parameter <span class="math inline">\(\theta\)</span> is linked with a hypothesis test of <span class="math inline">\(H_0:\theta = c\)</span> versus <span class="math inline">\(H_a:\theta \neq c\)</span> tested at level
<span class="math inline">\(\alpha\)</span>.</p>
<ul>
<li>Any point that lies within the <span class="math inline">\(100(1-\alpha)\%\)</span> confidence interval for <span class="math inline">\(\theta\)</span> represents a value of <span class="math inline">\(c\)</span> for which the associated null hypothesis would not be rejected at significance level <span class="math inline">\(\theta\)</span>.</li>
<li>Any point outside of the confidence interval is a value of <span class="math inline">\(c\)</span> for which the associated null hypothesis would be rejected.</li>
</ul>
<p>Similar relationships hold for one-sided CIs and hypothesis tests.</p>
<p><strong>Example:</strong></p>
<p>Consider the 95% confidence interval for <span class="math inline">\(\mu\)</span> we previously
constructed: [-0.070,1.171].</p>
<p>That interval is conceptually linked to the statistical test of <span class="math inline">\(H_0:\mu = c\)</span> versus <span class="math inline">\(H_a:\mu \neq c\)</span> using <span class="math inline">\(\alpha =0.05\)</span>.</p>
<p>We would reject <span class="math inline">\(H_0\)</span> for any hypothesized values of <span class="math inline">\(c\)</span> less than -0.070 or more than 1.171. We would fail to reject <span class="math inline">\(H_0\)</span> for any values of <span class="math inline">\(c\)</span> between -0.070 and 1.171.</p>
<p>A confidence interval provides us with much of the same information as a hypothesis test, but it doesn’t provide the p-value or allow us to do hypothesis tests at different significance levels.</p>
<p>Confidence intervals are often preferred over hypothesis tests because they provide additional information in the form of plausible parameters values while giving us enough information to perform a hypothesis test.</p>
<!-- ## Bootstrap Confidence Intervals -->
<!-- The conventional parametric confidence interval assumes we know the -->
<!-- distribution of the population in order to find a pivotal quantity. The -->
<!-- population distribution is needed to determine the sampling distribution -->
<!-- of our statistic. -->
<!-- A bootstrap confidence interval can be constructed if the population -->
<!-- distribution is unknown. -->
<!-- How would we estimate the sampling distribution of a statistic without -->
<!-- statistical theory? -->
<!-- Estimating the Sampling Distribution of a statistic for a Known -->
<!-- Population -->
<!--     Obtain a random sample of size n from the population. -->
<!--     Compute the statistic for the random sample. -->
<!--     Perform steps 1 and 2 many times. -->
<!--     Determine the empirical distribution of the statistics from the independent samples. -->
<!-- Consider a comparison of the estimated sampling distribution (the -->
<!-- empirical distribution) and the true sampling distribution of Y ̅ when -->
<!-- sampling n=10 observations from a N(0,1) population. -->
<!-- The bootstrap method allows us to approximate the sampling distribution -->
<!-- of a statistic by using the observed data to produce simulated data -->
<!-- sets. -->
<!-- The bootstrap method uses the observed data to approximate the shape, -->
<!-- spread, and bias of the sampling distribution of a statistic. -->
<!-- A bootstrap sample is a sample with replacement of size n from the -->
<!-- observed data. -->
<!-- Estimating the Sampling Distribution Using the Bootstrap Method Obtain a -->
<!-- bootstrap sample of the observed data by selecting with replacement a -->
<!-- sample of size n from the observed data. Compute the statistic for the -->
<!-- random sample. Perform steps 1 and 2 many times. Determine the empirical -->
<!-- distribution of the statistics from the independent bootstrap samples -->
<!-- (a.k.a., the bootstrap distribution). -->
<!-- Consider a comparison of the bootstrap, empirical, and true sampling -->
<!-- distributions of Y ̅ when the data are obtained from a N(0,1) -->
<!-- population. -->
<!-- A 100(1-α)% confidence interval for a target parameter θ can be obtained -->
<!-- by determining the α/2 and 1-α/2 quantiles of the bootstrap distribution -->
<!-- for θ ̂. E.g., a 95% CI for a population mean μ could be obtained by -->
<!-- taking the 0.025 and 0.975 quantiles of the bootstrap distribution for y -->
<!-- ̅. -->
<!-- Example (continued): Continuing our previous example, the 95% bootstrap -->
<!-- confidence interval for μ is [-0.162, 1.109]. -->
<!-- > quantile(boot_ybar, prob = c(0.025, 0.975)) 2.5% 97.5% -0.1610048 -->
<!-- > 1.1085468 -->
<!-- The parametric 95% confidence interval is [-0.070,1.171]. -->
<!-- The parametric and bootstrap methods of constructing confidence -->
<!-- intervals will NOT produce identical intervals, though the intervals -->
<!-- should be similar if the distributional assumptions are satisfied. -->
<!-- If you are unsure whether the distributional assumptions are satisfied, -->
<!-- you should use the bootstrap method to construct your confidence -->
<!-- interval. -->
<!-- Example: Grogan and Wirth (1981) provide data on the wing length in -->
<!-- millimeters of nine members of a species of midge (small, two-winged -->
<!-- flies). From these nine measurements, we wish to make inference about -->
<!-- the population mean μ. Assume that the data are an i.i.d. sample from a -->
<!-- N(μ,σ\^2) population with μ and σ\^2 unknown. The data are: 1.64, 1.70, -->
<!-- 1.72, 1.74, 1.82, 1.82, 1.82, 1.90, 2.08 -->
<!--     Construct a 98% parametric confidence interval for μ. -->
<!--     Construct a 98% bootstrap confidence interval for μ. -->
<!--     Perform a hypothesis test of whether μ>2 at α=0.02. -->

<!--  -->
<!-- # References {-} -->
<!--  -->
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-boos_stefanski_2011_pvalues" class="csl-entry">
Boos, Dennis D., and Leonard A. Stefanski. 2011. <span>“P-Value Precision and Reproducibility.”</span> <em>The American Statistician</em> 65 (4): 213–21. <a href="https://doi.org/10.1198/tas.2011.10129">https://doi.org/10.1198/tas.2011.10129</a>.
</div>
<div id="ref-gibson_pvalue" class="csl-entry">
Gibson, Eric W. 2021. <span>“The Role of p-Values in Judging the Strength of Evidence and Realistic Replication Expectations.”</span> <em>Statistics in Biopharmaceutical Research</em> 13 (1): 6–18. <a href="https://doi.org/10.1080/19466315.2020.1724560">https://doi.org/10.1080/19466315.2020.1724560</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="prob-review.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["A-Progessive-Introduction-to-Linear-Models.pdf", "A-Progessive-Introduction-to-Linear-Models.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
